{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dz3p4nhwSOh_"
      },
      "source": [
        "# Introduction to PyTorch: From Tensors to Training Neural Networks\n",
        "\n",
        "**Based on Sebastian Raschka's PyTorch Tutorial**\n",
        "\n",
        "This notebook will introduce you to the essential concepts of PyTorch in a hands-on, interactive way. By the end of this tutorial, you'll understand:\n",
        "\n",
        "1. What PyTorch is and why it's popular\n",
        "2. Tensors - the fundamental data structure\n",
        "3. Automatic differentiation (autograd)\n",
        "4. Building neural networks\n",
        "5. Training models with a typical training loop\n",
        "6. Working with GPUs\n",
        "\n",
        "---\n",
        "\n",
        "## Part 1: What is PyTorch?\n",
        "\n",
        "PyTorch is an open-source Python deep learning library that has become the most widely used framework for  and model development since 2019. It offers the perfect balance between:\n",
        "- **Ease of use**: Intuitive, Python-native API\n",
        "- **Flexibility**: Full control for customization\n",
        "- **Performance**: GPU acceleration for fast training\n",
        "\n",
        "### The Three Core Components of PyTorch:\n",
        "\n",
        "1. **Tensor Library**: Like NumPy but with GPU support\n",
        "2. **Automatic Differentiation (Autograd)**: Computes gradients automatically for backpropagation\n",
        "3. **Deep Learning Library**: Pre-built modules, loss functions, and optimizers\n",
        "\n",
        "Let's start by installing and checking PyTorch."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "szlsrDiFSOiF",
        "outputId": "200d1dfa-8f49-43f5-feac-e1c61e8f06b0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PyTorch version: 2.9.0+cu126\n",
            "CUDA (GPU) available: False\n"
          ]
        }
      ],
      "source": [
        "# Install PyTorch (uncomment if needed)\n",
        "# !pip install torch\n",
        "\n",
        "# Import PyTorch\n",
        "import torch\n",
        "import numpy as np\n",
        "\n",
        "# Check PyTorch version\n",
        "print(f\"PyTorch version: {torch.__version__}\")\n",
        "\n",
        "# Check if GPU is available\n",
        "print(f\"CUDA (GPU) available: {torch.cuda.is_available()}\")\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"Number of GPUs: {torch.cuda.device_count()}\")\n",
        "    print(f\"Current GPU: {torch.cuda.get_device_name(0)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cBnZII0HSOiJ"
      },
      "source": [
        "---\n",
        "\n",
        "## Part 2: Understanding Tensors\n",
        "\n",
        "**What are tensors?**\n",
        "\n",
        "Tensors are the fundamental data structure in PyTorch - they're multi-dimensional arrays that can store data:\n",
        "\n",
        "- **Scalar (0D tensor)**: Just a number (e.g., 5)\n",
        "- **Vector (1D tensor)**: Array of numbers (e.g., [1, 2, 3])\n",
        "- **Matrix (2D tensor)**: Table of numbers (e.g., [[1, 2], [3, 4]])\n",
        "- **3D+ tensors**: Higher-dimensional arrays\n",
        "\n",
        "### Creating Tensors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "ySe2sZcSSOiL",
        "outputId": "a1ee088e-fc5e-4808-b9ae-1eafcb78b1f8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Scalar: 1\n",
            "Shape: torch.Size([])\n",
            "\n",
            "Vector: tensor([1, 2, 3])\n",
            "Shape: torch.Size([3])\n",
            "\n",
            "Matrix:\n",
            "tensor([[1, 2, 3],\n",
            "        [4, 5, 6]])\n",
            "Shape: torch.Size([2, 3])\n",
            "\n",
            "3D Tensor:\n",
            "tensor([[[1, 2],\n",
            "         [3, 4]],\n",
            "\n",
            "        [[5, 6],\n",
            "         [7, 8]]])\n",
            "Shape: torch.Size([2, 2, 2])\n"
          ]
        }
      ],
      "source": [
        "# Create a scalar (0D tensor)\n",
        "tensor0d = torch.tensor(1)\n",
        "print(f\"Scalar: {tensor0d}\")\n",
        "print(f\"Shape: {tensor0d.shape}\\n\")\n",
        "\n",
        "# Create a vector (1D tensor)\n",
        "tensor1d = torch.tensor([1, 2, 3])\n",
        "print(f\"Vector: {tensor1d}\")\n",
        "print(f\"Shape: {tensor1d.shape}\\n\")\n",
        "\n",
        "# Create a matrix (2D tensor)\n",
        "tensor2d = torch.tensor([[1, 2, 3],\n",
        "                         [4, 5, 6]])\n",
        "print(f\"Matrix:\\n{tensor2d}\")\n",
        "print(f\"Shape: {tensor2d.shape}\\n\")\n",
        "\n",
        "# Create a 3D tensor\n",
        "tensor3d = torch.tensor([[[1, 2], [3, 4]],\n",
        "                         [[5, 6], [7, 8]]])\n",
        "print(f\"3D Tensor:\\n{tensor3d}\")\n",
        "print(f\"Shape: {tensor3d.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7OE4HyBFSOiN"
      },
      "source": [
        "### Exercise 1: Create Your Own Tensors\n",
        "\n",
        "**TODO**: Create the following tensors:\n",
        "1. A scalar with value 42\n",
        "2. A 1D tensor with values [10, 20, 30, 40, 50]\n",
        "3. A 2Ã—2 identity matrix [[1, 0], [0, 1]]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "6icsqBkcSOiP",
        "outputId": "ba64b871-8b9e-47d0-a0ea-6c007c9cc0e0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "My scalar: 42\n",
            "My vector: tensor([10, 20, 30, 40, 50])\n",
            "My matrix:\n",
            "tensor([[1, 0],\n",
            "        [0, 1]])\n"
          ]
        }
      ],
      "source": [
        "# Your code here\n",
        "my_scalar = torch.tensor(42)\n",
        "my_vector = torch.tensor([10, 20, 30, 40, 50])\n",
        "my_matrix = torch.tensor([[1, 0], [0, 1]])\n",
        "\n",
        "print(f\"My scalar: {my_scalar}\")\n",
        "print(f\"My vector: {my_vector}\")\n",
        "print(f\"My matrix:\\n{my_matrix}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EFMnDCMnSOiQ"
      },
      "source": [
        "### Tensor Data Types\n",
        "\n",
        "PyTorch tensors have data types (dtypes) that specify how the data is stored:\n",
        "- **Integers**: `torch.int64` (default for Python integers)\n",
        "- **Floats**: `torch.float32` (default for Python floats, most common in deep learning)\n",
        "\n",
        "**Why float32?** It balances precision and computational efficiency, and GPUs are optimized for it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "U7zrw4MDSOiR",
        "outputId": "b3d9af3b-ea9e-46ec-e4f7-e5d4dc87236f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Integer tensor dtype: torch.int64\n",
            "Float tensor dtype: torch.float32\n",
            "Converted dtype: torch.float32\n"
          ]
        }
      ],
      "source": [
        "# Check data types\n",
        "int_tensor = torch.tensor([1, 2, 3])\n",
        "print(f\"Integer tensor dtype: {int_tensor.dtype}\")\n",
        "\n",
        "float_tensor = torch.tensor([1.0, 2.0, 3.0])\n",
        "print(f\"Float tensor dtype: {float_tensor.dtype}\")\n",
        "\n",
        "# Convert data types\n",
        "converted = int_tensor.to(torch.float32)\n",
        "print(f\"Converted dtype: {converted.dtype}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TrKyLUXwSOiS"
      },
      "source": [
        "### Common Tensor Operations\n",
        "\n",
        "PyTorch provides a NumPy-like API for tensor operations."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "325ZwRKESOiT",
        "outputId": "e9ec51e6-28b9-4705-a0a1-eb36b84b6091",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original tensor:\n",
            "tensor([[1, 2, 3],\n",
            "        [4, 5, 6]])\n",
            "Shape: torch.Size([2, 3])\n",
            "\n",
            "Reshaped (3Ã—2):\n",
            "tensor([[1, 2],\n",
            "        [3, 4],\n",
            "        [5, 6]])\n",
            "\n",
            "Transposed:\n",
            "tensor([[1, 4],\n",
            "        [2, 5],\n",
            "        [3, 6]])\n",
            "\n",
            "Matrix multiplication (tensor @ tensor.T):\n",
            "tensor([[14, 32],\n",
            "        [32, 77]])\n"
          ]
        }
      ],
      "source": [
        "# Create a 2D tensor\n",
        "tensor = torch.tensor([[1, 2, 3],\n",
        "                       [4, 5, 6]])\n",
        "\n",
        "print(f\"Original tensor:\\n{tensor}\")\n",
        "print(f\"Shape: {tensor.shape}\\n\")\n",
        "\n",
        "# Reshape/View - change dimensions\n",
        "reshaped = tensor.view(3, 2)\n",
        "print(f\"Reshaped (3Ã—2):\\n{reshaped}\\n\")\n",
        "\n",
        "# Transpose - flip across diagonal\n",
        "transposed = tensor.T\n",
        "print(f\"Transposed:\\n{transposed}\\n\")\n",
        "\n",
        "# Matrix multiplication\n",
        "result = tensor @ tensor.T\n",
        "print(f\"Matrix multiplication (tensor @ tensor.T):\\n{result}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ixtSR0R6SOiU"
      },
      "source": [
        "### Exercise 2: Tensor Operations\n",
        "\n",
        "**TODO**: Given the tensor below:\n",
        "1. Reshape it to shape (4, 3)\n",
        "2. Compute the transpose\n",
        "3. Find the sum of all elements using `.sum()`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "O3cke3rdSOiV",
        "outputId": "22908087-b6ce-4443-c76e-12d3e44797f5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reshaped:\n",
            "tensor([[ 1,  2,  3],\n",
            "        [ 4,  5,  6],\n",
            "        [ 7,  8,  9],\n",
            "        [10, 11, 12]])\n",
            "\n",
            "Transposed:\n",
            "tensor([[ 1,  5,  9],\n",
            "        [ 2,  6, 10],\n",
            "        [ 3,  7, 11],\n",
            "        [ 4,  8, 12]])\n",
            "\n",
            "Sum of all elements: 78\n"
          ]
        }
      ],
      "source": [
        "practice_tensor = torch.tensor([[1, 2, 3, 4],\n",
        "                                [5, 6, 7, 8],\n",
        "                                [9, 10, 11, 12]])\n",
        "\n",
        "# Your code here\n",
        "reshaped = practice_tensor.view(4, 3)\n",
        "transposed = practice_tensor.T\n",
        "total_sum = practice_tensor.sum()\n",
        "\n",
        "print(f\"Reshaped:\\n{reshaped}\\n\")\n",
        "print(f\"Transposed:\\n{transposed}\\n\")\n",
        "print(f\"Sum of all elements: {total_sum}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kq2XO0V-SOiW"
      },
      "source": [
        "---\n",
        "\n",
        "## Part 3: Computation Graphs and Automatic Differentiation\n",
        "\n",
        "### What is a Computation Graph?\n",
        "\n",
        "A computation graph tracks the sequence of operations needed to compute an output. PyTorch builds this graph automatically to compute gradients during backpropagation.\n",
        "\n",
        "**Example**: Simple logistic regression forward pass\n",
        "```\n",
        "z = x1 * w1 + b     (net input)\n",
        "a = sigmoid(z)      (activation)\n",
        "loss = BCE(a, y)    (binary cross-entropy loss)\n",
        "```\n",
        "\n",
        "### Automatic Differentiation (Autograd)\n",
        "\n",
        "PyTorch's autograd engine automatically computes gradients - no manual calculus needed!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "V2nh6Zf9SOiW",
        "outputId": "fdd976ec-35f8-46c3-cba9-01eb50735d08",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0852\n",
            "Gradient w.r.t. w1: tensor([-0.0898])\n",
            "Gradient w.r.t. b: tensor([-0.0817])\n"
          ]
        }
      ],
      "source": [
        "import torch.nn.functional as F\n",
        "\n",
        "# Set up a simple computation\n",
        "y = torch.tensor([1.0])  # true label\n",
        "x1 = torch.tensor([1.1])  # input feature\n",
        "\n",
        "# Parameters - requires_grad=True enables gradient tracking\n",
        "w1 = torch.tensor([2.2], requires_grad=True)\n",
        "b = torch.tensor([0.0], requires_grad=True)\n",
        "\n",
        "# Forward pass\n",
        "z = x1 * w1 + b\n",
        "a = torch.sigmoid(z)\n",
        "loss = F.binary_cross_entropy(a, y)\n",
        "\n",
        "print(f\"Loss: {loss.item():.4f}\")\n",
        "\n",
        "# Backward pass - compute gradients automatically!\n",
        "loss.backward()\n",
        "\n",
        "print(f\"Gradient w.r.t. w1: {w1.grad}\")\n",
        "print(f\"Gradient w.r.t. b: {b.grad}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d8I59TNKSOiX"
      },
      "source": [
        "**Key Points**:\n",
        "- `requires_grad=True`: Tells PyTorch to track operations for gradient computation\n",
        "- `.backward()`: Computes all gradients automatically\n",
        "- `.grad`: Stores the computed gradient for each tensor\n",
        "\n",
        "This is the magic that makes training neural networks easy!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I8ZqcSuiSOiX"
      },
      "source": [
        "### Exercise 3: Manual Gradient Computation\n",
        "\n",
        "**TODO**: Complete the forward pass and compute gradients\n",
        "1. Compute `z = x * w + b`\n",
        "2. Compute the loss: `loss = (z - target)**2` (mean squared error)\n",
        "3. Call `.backward()` to compute gradients\n",
        "4. Print the gradients"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "4WclyzJpSOiX",
        "outputId": "69b087a2-ed02-4621-ce95-86a7cbcfa75c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 9.0000\n",
            "Gradient w.r.t. w: tensor([-12.])\n",
            "Gradient w.r.t. b: tensor([-6.])\n"
          ]
        }
      ],
      "source": [
        "# Setup\n",
        "x = torch.tensor([2.0])\n",
        "target = torch.tensor([5.0])\n",
        "w = torch.tensor([1.0], requires_grad=True)\n",
        "b = torch.tensor([0.0], requires_grad=True)\n",
        "\n",
        "# Your code here\n",
        "z = x * w + b\n",
        "loss = (z - target)**2\n",
        "\n",
        "# TODO: call backward to compute gradients\n",
        "loss.backward()\n",
        "\n",
        "print(f\"Loss: {loss.item():.4f}\")\n",
        "print(f\"Gradient w.r.t. w: {w.grad}\")\n",
        "print(f\"Gradient w.r.t. b: {b.grad}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dWXgXvPmSOiY"
      },
      "source": [
        "---\n",
        "\n",
        "## Part 4: Building Neural Networks\n",
        "\n",
        "In PyTorch, we build neural networks by subclassing `torch.nn.Module`. This gives us:\n",
        "- Automatic parameter tracking\n",
        "- Easy layer composition\n",
        "- Built-in training/evaluation modes\n",
        "\n",
        "### Anatomy of a PyTorch Model\n",
        "\n",
        "```python\n",
        "class MyModel(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        # Define layers here\n",
        "    \n",
        "    def forward(self, x):\n",
        "        # Define forward pass here\n",
        "        return output\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "BNMbjv6ZSOiY",
        "outputId": "7cfe29a0-211a-4d1c-ccdb-9157d54c77d5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NeuralNetwork(\n",
            "  (layers): Sequential(\n",
            "    (0): Linear(in_features=50, out_features=30, bias=True)\n",
            "    (1): ReLU()\n",
            "    (2): Linear(in_features=30, out_features=20, bias=True)\n",
            "    (3): ReLU()\n",
            "    (4): Linear(in_features=20, out_features=3, bias=True)\n",
            "  )\n",
            ")\n",
            "\n",
            "Total trainable parameters: 2213\n"
          ]
        }
      ],
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "class NeuralNetwork(nn.Module):\n",
        "    def __init__(self, num_inputs, num_outputs):\n",
        "        super().__init__()\n",
        "        self.layers = nn.Sequential(\n",
        "            # First hidden layer\n",
        "            nn.Linear(num_inputs, 30),\n",
        "            nn.ReLU(),\n",
        "\n",
        "            # Second hidden layer\n",
        "            nn.Linear(30, 20),\n",
        "            nn.ReLU(),\n",
        "\n",
        "            # Output layer\n",
        "            nn.Linear(20, num_outputs)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.layers(x)\n",
        "\n",
        "# Create a model\n",
        "model = NeuralNetwork(num_inputs=50, num_outputs=3)\n",
        "print(model)\n",
        "\n",
        "# Count parameters\n",
        "num_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "print(f\"\\nTotal trainable parameters: {num_params}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9aCdkm5qSOiZ"
      },
      "source": [
        "### Making Predictions\n",
        "\n",
        "To use the model, we pass data through it. The model returns **logits** (raw scores), which we can convert to probabilities."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "K3YkT1u6SOiZ",
        "outputId": "ade7b98b-3215-4206-d94a-cb3358953da9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logits: tensor([[ 0.1065, -0.0743,  0.1053]], grad_fn=<AddmmBackward0>)\n",
            "\n",
            "Probabilities: tensor([[0.3529, 0.2946, 0.3525]], grad_fn=<SoftmaxBackward0>)\n",
            "Sum of probabilities: 1.0000\n",
            "Predicted class: 0\n"
          ]
        }
      ],
      "source": [
        "# Set random seed for reproducibility\n",
        "torch.manual_seed(123)\n",
        "\n",
        "# Create random input (1 sample, 50 features)\n",
        "X = torch.rand((1, 50))\n",
        "\n",
        "# Forward pass - get logits\n",
        "logits = model(X)\n",
        "print(f\"Logits: {logits}\\n\")\n",
        "\n",
        "# Convert to probabilities with softmax\n",
        "probabilities = torch.softmax(logits, dim=1)\n",
        "print(f\"Probabilities: {probabilities}\")\n",
        "print(f\"Sum of probabilities: {probabilities.sum():.4f}\")\n",
        "\n",
        "# Get predicted class\n",
        "predicted_class = torch.argmax(probabilities, dim=1)\n",
        "print(f\"Predicted class: {predicted_class.item()}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UFrX7I8hSOiZ"
      },
      "source": [
        "### Exercise 4: Build Your Own Network\n",
        "\n",
        "**TODO**: Create a neural network with:\n",
        "- Input size: 10\n",
        "- Hidden layer 1: 64 neurons with ReLU activation\n",
        "- Hidden layer 2: 32 neurons with ReLU activation  \n",
        "- Output size: 5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "2I1r1C8wSOia",
        "outputId": "cc89167a-5582-4518-f1c5-d496e048205a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MyNetwork(\n",
            "  (layers): Sequential(\n",
            "    (0): Linear(in_features=10, out_features=64, bias=True)\n",
            "    (1): ReLU()\n",
            "    (2): Linear(in_features=64, out_features=32, bias=True)\n",
            "    (3): ReLU()\n",
            "    (4): Linear(in_features=32, out_features=5, bias=True)\n",
            "  )\n",
            ")\n",
            "\n",
            "Output shape: torch.Size([1, 5])\n"
          ]
        }
      ],
      "source": [
        "class MyNetwork(nn.Module):\n",
        "    def __init__(self, input_size, output_size):\n",
        "        super().__init__()\n",
        "        # TODO: Define your layers using nn.Sequential\n",
        "        self.layers = nn.Sequential(\n",
        "            nn.Linear(input_size, 64),\n",
        "            nn.ReLU(),\n",
        "\n",
        "            nn.Linear(64, 32),\n",
        "            nn.ReLU(),\n",
        "\n",
        "            nn.Linear(32, output_size)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.layers(x)\n",
        "\n",
        "# Create and test your model\n",
        "my_model = MyNetwork(10, 5)\n",
        "print(my_model)\n",
        "\n",
        "# Test with random input\n",
        "test_input = torch.rand((1, 10))\n",
        "output = my_model(test_input)\n",
        "print(f\"\\nOutput shape: {output.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gJ4L1eoiSOia"
      },
      "source": [
        "---\n",
        "\n",
        "## Part 5: Data Loading\n",
        "\n",
        "PyTorch provides `Dataset` and `DataLoader` classes for efficient data loading:\n",
        "\n",
        "1. **Dataset**: Defines how to access individual samples\n",
        "2. **DataLoader**: Batches data, shuffles, and loads in parallel\n",
        "\n",
        "### Creating a Custom Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "BfuQLmO_SOib",
        "outputId": "2ef20e7d-03b9-49be-bbdc-98c07a6d6c9e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training samples: 5\n",
            "Test samples: 2\n"
          ]
        }
      ],
      "source": [
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "class ToyDataset(Dataset):\n",
        "    def __init__(self, X, y):\n",
        "        self.features = X\n",
        "        self.labels = y\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        # Return one sample\n",
        "        return self.features[index], self.labels[index]\n",
        "\n",
        "    def __len__(self):\n",
        "        # Return dataset size\n",
        "        return len(self.labels)\n",
        "\n",
        "# Create toy data\n",
        "X_train = torch.tensor([[-1.2, 3.1],\n",
        "                        [-0.9, 2.9],\n",
        "                        [-0.5, 2.6],\n",
        "                        [2.3, -1.1],\n",
        "                        [2.7, -1.5]])\n",
        "y_train = torch.tensor([0, 0, 0, 1, 1])\n",
        "\n",
        "X_test = torch.tensor([[-0.8, 2.8],\n",
        "                       [2.6, -1.6]])\n",
        "y_test = torch.tensor([0, 1])\n",
        "\n",
        "# Create datasets\n",
        "train_dataset = ToyDataset(X_train, y_train)\n",
        "test_dataset = ToyDataset(X_test, y_test)\n",
        "\n",
        "print(f\"Training samples: {len(train_dataset)}\")\n",
        "print(f\"Test samples: {len(test_dataset)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_cmg3_yLSOib"
      },
      "source": [
        "### Creating DataLoaders"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "dRyIRzQFSOib",
        "outputId": "63e26aa6-2980-48d1-9767-579bad0d15e4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training batches:\n",
            "Batch 1: Features shape=torch.Size([2, 2]), Labels=tensor([1, 0])\n",
            "Batch 2: Features shape=torch.Size([2, 2]), Labels=tensor([0, 0])\n"
          ]
        }
      ],
      "source": [
        "# Set seed for reproducible shuffling\n",
        "torch.manual_seed(123)\n",
        "\n",
        "# Create data loaders\n",
        "train_loader = DataLoader(\n",
        "    dataset=train_dataset,\n",
        "    batch_size=2,\n",
        "    shuffle=True,\n",
        "    drop_last=True  # Drop last incomplete batch\n",
        ")\n",
        "\n",
        "test_loader = DataLoader(\n",
        "    dataset=test_dataset,\n",
        "    batch_size=2,\n",
        "    shuffle=False\n",
        ")\n",
        "\n",
        "# Iterate over batches\n",
        "print(\"Training batches:\")\n",
        "for batch_idx, (features, labels) in enumerate(train_loader):\n",
        "    print(f\"Batch {batch_idx + 1}: Features shape={features.shape}, Labels={labels}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ul3IgbBaSOib"
      },
      "source": [
        "---\n",
        "\n",
        "## Part 6: The Training Loop\n",
        "\n",
        "Now we combine everything: model, data, loss function, and optimizer.\n",
        "\n",
        "### Key Components:\n",
        "1. **Model**: The neural network\n",
        "2. **Loss Function**: Measures prediction error (e.g., cross-entropy)\n",
        "3. **Optimizer**: Updates weights to minimize loss (e.g., SGD, Adam)\n",
        "4. **Training Loop**: Iterate over data, compute loss, update weights"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "nqfe20vRSOic",
        "outputId": "8554581e-3a18-43a2-d223-629290c6f474",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3 | Batch 1/2 | Loss: 0.7487\n",
            "Epoch 1/3 | Batch 2/2 | Loss: 0.6450\n",
            "Epoch 2/3 | Batch 1/2 | Loss: 0.4423\n",
            "Epoch 2/3 | Batch 2/2 | Loss: 0.1256\n",
            "Epoch 3/3 | Batch 1/2 | Loss: 0.0269\n",
            "Epoch 3/3 | Batch 2/2 | Loss: 0.0043\n",
            "\n",
            "Training complete!\n"
          ]
        }
      ],
      "source": [
        "import torch.nn.functional as F\n",
        "\n",
        "# Set seed for reproducibility\n",
        "torch.manual_seed(123)\n",
        "\n",
        "# Create model (2 inputs, 2 outputs for binary classification)\n",
        "model = NeuralNetwork(num_inputs=2, num_outputs=2)\n",
        "\n",
        "# Define optimizer (Stochastic Gradient Descent)\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.5)\n",
        "\n",
        "# Training loop\n",
        "num_epochs = 3\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()  # Set model to training mode\n",
        "\n",
        "    for batch_idx, (features, labels) in enumerate(train_loader):\n",
        "        # Forward pass\n",
        "        logits = model(features)\n",
        "        loss = F.cross_entropy(logits, labels)\n",
        "\n",
        "        # Backward pass\n",
        "        optimizer.zero_grad()  # Reset gradients\n",
        "        loss.backward()  # Compute gradients\n",
        "        optimizer.step()  # Update weights\n",
        "\n",
        "        # Logging\n",
        "        print(f\"Epoch {epoch+1}/{num_epochs} | \"\n",
        "              f\"Batch {batch_idx+1}/{len(train_loader)} | \"\n",
        "              f\"Loss: {loss.item():.4f}\")\n",
        "\n",
        "print(\"\\nTraining complete!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RWaFK_DbSOid"
      },
      "source": [
        "### Model Evaluation\n",
        "\n",
        "After training, we evaluate the model's accuracy."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "FtTyrBEUSOid",
        "outputId": "8483919f-0865-414d-fce7-6dfffd03bb48",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Accuracy: 100.00%\n",
            "Test Accuracy: 100.00%\n"
          ]
        }
      ],
      "source": [
        "def compute_accuracy(model, dataloader):\n",
        "    model.eval()  # Set to evaluation mode\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    with torch.no_grad():  # Disable gradient computation\n",
        "        for features, labels in dataloader:\n",
        "            logits = model(features)\n",
        "            predictions = torch.argmax(logits, dim=1)\n",
        "            correct += (predictions == labels).sum().item()\n",
        "            total += len(labels)\n",
        "\n",
        "    return correct / total\n",
        "\n",
        "# Evaluate on training and test sets\n",
        "train_acc = compute_accuracy(model, train_loader)\n",
        "test_acc = compute_accuracy(model, test_loader)\n",
        "\n",
        "print(f\"Training Accuracy: {train_acc * 100:.2f}%\")\n",
        "print(f\"Test Accuracy: {test_acc * 100:.2f}%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fy3C_nVxSOid"
      },
      "source": [
        "### Exercise 5: Complete Training Loop\n",
        "\n",
        "**TODO**: Fill in the missing parts of the training loop below"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "UpzWiVvwSOid",
        "outputId": "507586b7-c478-4c90-8815-0fb9ae18119c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5 | Loss: 0.6098\n",
            "Epoch 2/5 | Loss: 0.6857\n",
            "Epoch 3/5 | Loss: 0.6857\n",
            "Epoch 4/5 | Loss: 0.6040\n",
            "Epoch 5/5 | Loss: 0.6098\n",
            "\n",
            "Final Test Accuracy: 100.00%\n"
          ]
        }
      ],
      "source": [
        "# Create a fresh model\n",
        "torch.manual_seed(42)\n",
        "student_model = NeuralNetwork(num_inputs=2, num_outputs=2)\n",
        "\n",
        "# TODO: Create an Adam optimizer with learning rate 0.01\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
        "\n",
        "num_epochs = 5\n",
        "for epoch in range(num_epochs):\n",
        "    student_model.train()\n",
        "\n",
        "    for features, labels in train_loader:\n",
        "        # TODO: Forward pass - compute logits\n",
        "        logits = student_model(features)\n",
        "\n",
        "        # TODO: Compute cross-entropy loss\n",
        "        loss = F.cross_entropy(logits, labels)\n",
        "\n",
        "        # TODO: Zero gradients\n",
        "        # TODO\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # TODO: Backward pass\n",
        "        # TODO\n",
        "        loss.backward()\n",
        "\n",
        "        # TODO: Update weights\n",
        "        # TODO\n",
        "        optimizer.step()\n",
        "\n",
        "    # Print loss every epoch\n",
        "    print(f\"Epoch {epoch+1}/{num_epochs} | Loss: {loss.item():.4f}\")\n",
        "\n",
        "# Evaluate\n",
        "final_acc = compute_accuracy(student_model, test_loader)\n",
        "print(f\"\\nFinal Test Accuracy: {final_acc * 100:.2f}%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6lZXbagQSOie"
      },
      "source": [
        "---\n",
        "\n",
        "## Part 7: Saving and Loading Models\n",
        "\n",
        "After training, we want to save our model for later use."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "l2yXtN3nSOii",
        "outputId": "2b52a777-255a-42d0-96d0-bf58f16d80a8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved!\n",
            "Model loaded!\n",
            "Loaded model test accuracy: 100.00%\n"
          ]
        }
      ],
      "source": [
        "# Save model\n",
        "torch.save(model.state_dict(), \"my_model.pth\")\n",
        "print(\"Model saved!\")\n",
        "\n",
        "# Load model\n",
        "loaded_model = NeuralNetwork(num_inputs=2, num_outputs=2)\n",
        "loaded_model.load_state_dict(torch.load(\"my_model.pth\", weights_only=True))\n",
        "loaded_model.eval()\n",
        "print(\"Model loaded!\")\n",
        "\n",
        "# Verify it works\n",
        "test_acc = compute_accuracy(loaded_model, test_loader)\n",
        "print(f\"Loaded model test accuracy: {test_acc * 100:.2f}%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dd6PGo2DSOij"
      },
      "source": [
        "---\n",
        "\n",
        "## Part 8: GPU Training (Optional)\n",
        "\n",
        "If you have a GPU available, you can significantly speed up training.\n",
        "\n",
        "### Key Concepts:\n",
        "1. Move model to GPU: `model.to(device)`\n",
        "2. Move data to GPU: `data.to(device)`\n",
        "3. All tensors must be on the same device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "xwt_VvanSOij",
        "outputId": "6629a3b5-8022-4b59-8e8a-c29386fdc844",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cpu\n",
            "Epoch 1/3 | Batch 1/2 | Loss: 0.7487\n",
            "Epoch 1/3 | Batch 2/2 | Loss: 0.6450\n",
            "Epoch 2/3 | Batch 1/2 | Loss: 0.4423\n",
            "Epoch 2/3 | Batch 2/2 | Loss: 0.1256\n",
            "Epoch 3/3 | Batch 1/2 | Loss: 0.0269\n",
            "Epoch 3/3 | Batch 2/2 | Loss: 0.0043\n"
          ]
        }
      ],
      "source": [
        "# Check GPU availability\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# Create model and move to GPU\n",
        "torch.manual_seed(123)\n",
        "gpu_model = NeuralNetwork(num_inputs=2, num_outputs=2)\n",
        "gpu_model.to(device)\n",
        "\n",
        "# Optimizer\n",
        "optimizer = torch.optim.SGD(gpu_model.parameters(), lr=0.5)\n",
        "\n",
        "# Training loop with GPU\n",
        "num_epochs = 3\n",
        "for epoch in range(num_epochs):\n",
        "    gpu_model.train()\n",
        "\n",
        "    for batch_idx, (features, labels) in enumerate(train_loader):\n",
        "        # Move data to GPU\n",
        "        features, labels = features.to(device), labels.to(device)\n",
        "\n",
        "        # Forward pass\n",
        "        logits = gpu_model(features)\n",
        "        loss = F.cross_entropy(logits, labels)\n",
        "\n",
        "        # Backward pass\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        print(f\"Epoch {epoch+1}/{num_epochs} | \"\n",
        "              f\"Batch {batch_idx+1}/{len(train_loader)} | \"\n",
        "              f\"Loss: {loss.item():.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uhylMnCrSOij"
      },
      "source": [
        "### Exercise 6: GPU Training\n",
        "\n",
        "**TODO**: Modify the accuracy computation function to work with GPU"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "vrMrxQSRSOik",
        "outputId": "2a130efd-78a3-483f-8d53-12dee364af6c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU Model Test Accuracy: 100.00%\n"
          ]
        }
      ],
      "source": [
        "def compute_accuracy_gpu(model, dataloader, device):\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for features, labels in dataloader:\n",
        "            # TODO: Move features and labels to device\n",
        "            features, labels = features.to(device), labels.to(device)\n",
        "\n",
        "            logits = model(features)\n",
        "            predictions = torch.argmax(logits, dim=1)\n",
        "            correct += (predictions == labels).sum().item()\n",
        "            total += len(labels)\n",
        "\n",
        "    return correct / total\n",
        "\n",
        "# Test your function\n",
        "test_acc = compute_accuracy_gpu(gpu_model, test_loader, device)\n",
        "print(f\"GPU Model Test Accuracy: {test_acc * 100:.2f}%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qlCP3mhQSOik"
      },
      "source": [
        "---\n",
        "\n",
        "## Part 9: Putting It All Together - Real Example\n",
        "\n",
        "Let's create a complete example with a slightly more complex dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "t0gmt8QCSOik",
        "outputId": "eca296a3-740f-49bc-95ef-38e25d5b68c2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training samples: 800\n",
            "Test samples: 200\n",
            "Features: 20\n",
            "Classes: 3\n"
          ]
        }
      ],
      "source": [
        "# Create synthetic dataset\n",
        "torch.manual_seed(42)\n",
        "\n",
        "# Generate 1000 samples with 20 features\n",
        "n_samples = 1000\n",
        "n_features = 20\n",
        "n_classes = 3\n",
        "\n",
        "# Random features and labels\n",
        "X = torch.randn(n_samples, n_features)\n",
        "y = torch.randint(0, n_classes, (n_samples,))\n",
        "\n",
        "# Split into train/test (80/20)\n",
        "n_train = int(0.8 * n_samples)\n",
        "X_train, X_test = X[:n_train], X[n_train:]\n",
        "y_train, y_test = y[:n_train], y[n_train:]\n",
        "\n",
        "print(f\"Training samples: {len(X_train)}\")\n",
        "print(f\"Test samples: {len(X_test)}\")\n",
        "print(f\"Features: {n_features}\")\n",
        "print(f\"Classes: {n_classes}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "EGVTnEygSOik",
        "outputId": "f79b7ce9-2554-4183-b1e6-f640374745b5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10 | Loss: 1.0995 | Train Acc: 35.12% | Test Acc: 37.00%\n",
            "Epoch 2/10 | Loss: 1.0927 | Train Acc: 38.75% | Test Acc: 36.50%\n",
            "Epoch 3/10 | Loss: 1.0874 | Train Acc: 41.12% | Test Acc: 39.50%\n",
            "Epoch 4/10 | Loss: 1.0835 | Train Acc: 42.50% | Test Acc: 38.00%\n",
            "Epoch 5/10 | Loss: 1.0788 | Train Acc: 43.12% | Test Acc: 34.50%\n",
            "Epoch 6/10 | Loss: 1.0741 | Train Acc: 43.88% | Test Acc: 34.00%\n",
            "Epoch 7/10 | Loss: 1.0689 | Train Acc: 45.25% | Test Acc: 35.50%\n",
            "Epoch 8/10 | Loss: 1.0634 | Train Acc: 45.88% | Test Acc: 34.50%\n",
            "Epoch 9/10 | Loss: 1.0579 | Train Acc: 47.62% | Test Acc: 35.50%\n",
            "Epoch 10/10 | Loss: 1.0517 | Train Acc: 47.75% | Test Acc: 35.00%\n"
          ]
        }
      ],
      "source": [
        "# Create datasets and loaders\n",
        "train_dataset = ToyDataset(X_train, y_train)\n",
        "test_dataset = ToyDataset(X_test, y_test)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
        "\n",
        "# Create model\n",
        "torch.manual_seed(42)\n",
        "model = NeuralNetwork(num_inputs=n_features, num_outputs=n_classes)\n",
        "model.to(device)\n",
        "\n",
        "# Define optimizer\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# Training loop\n",
        "num_epochs = 10\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "\n",
        "    for features, labels in train_loader:\n",
        "        features, labels = features.to(device), labels.to(device)\n",
        "\n",
        "        logits = model(features)\n",
        "        loss = F.cross_entropy(logits, labels)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    avg_loss = total_loss / len(train_loader)\n",
        "\n",
        "    # Evaluate every epoch\n",
        "    train_acc = compute_accuracy_gpu(model, train_loader, device)\n",
        "    test_acc = compute_accuracy_gpu(model, test_loader, device)\n",
        "\n",
        "    print(f\"Epoch {epoch+1}/{num_epochs} | \"\n",
        "          f\"Loss: {avg_loss:.4f} | \"\n",
        "          f\"Train Acc: {train_acc*100:.2f}% | \"\n",
        "          f\"Test Acc: {test_acc*100:.2f}%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1eI3SJEzSOil"
      },
      "source": [
        "---\n",
        "\n",
        "## Summary\n",
        "\n",
        "Congratulations! You've learned the essential PyTorch concepts:\n",
        "\n",
        "### âœ… Key Takeaways:\n",
        "\n",
        "1. **Tensors**: Multi-dimensional arrays (similar to NumPy) with GPU support\n",
        "2. **Autograd**: Automatic gradient computation for backpropagation\n",
        "3. **nn.Module**: Base class for building neural networks\n",
        "4. **DataLoader**: Efficient batching and data loading\n",
        "5. **Training Loop**:\n",
        "   - Forward pass â†’ Compute loss\n",
        "   - Backward pass â†’ Compute gradients\n",
        "   - Optimizer step â†’ Update weights\n",
        "6. **GPU Support**: Simple `.to(device)` for acceleration\n",
        "\n",
        "### ðŸŽ¯ Next Steps:\n",
        "\n",
        "- Experiment with different architectures\n",
        "- Try different optimizers (Adam, AdamW, etc.)\n",
        "- Explore real datasets (MNIST, CIFAR-10)\n",
        "- Learn about CNNs, RNNs, Transformers\n",
        "- Build your own projects!\n",
        "\n",
        "### ðŸ“š Further Resources:\n",
        "\n",
        "- **Official PyTorch Tutorials**: https://pytorch.org/tutorials/\n",
        "- **PyTorch Documentation**: https://pytorch.org/docs/\n",
        "- **Original Tutorial**: https://sebastianraschka.com/teaching/pytorch-1h/\n",
        "- **Books**:\n",
        "  - *Deep Learning with PyTorch* by Stevens, Antiga, and Viehmann\n",
        "  - *Machine Learning with PyTorch and Scikit-Learn* by Raschka et al."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L7RMNI62SOim"
      },
      "source": [
        "---\n",
        "\n",
        "## Bonus Exercise: Build a Complete Project\n",
        "\n",
        "**Challenge**: Create a neural network to classify the Iris dataset\n",
        "\n",
        "**Steps**:\n",
        "1. Load the Iris dataset (sklearn)\n",
        "2. Create PyTorch datasets and dataloaders\n",
        "3. Build a neural network\n",
        "4. Train for multiple epochs\n",
        "5. Evaluate and report accuracy\n",
        "\n",
        "**Starter code below:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "id": "SOovVrO7SOin",
        "outputId": "1ebaad12-696e-4052-90a7-da66e86c31fa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset: 120 training, 30 test samples\n",
            "Features: 4, Classes: 3\n"
          ]
        }
      ],
      "source": [
        "# Bonus challenge - Iris classification\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Load Iris dataset\n",
        "iris = load_iris()\n",
        "X, y = iris.data, iris.target\n",
        "\n",
        "# Split and scale\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "# Convert to tensors\n",
        "X_train = torch.FloatTensor(X_train)\n",
        "X_test = torch.FloatTensor(X_test)\n",
        "y_train = torch.LongTensor(y_train)\n",
        "y_test = torch.LongTensor(y_test)\n",
        "\n",
        "print(f\"Dataset: {len(X_train)} training, {len(X_test)} test samples\")\n",
        "print(f\"Features: {X_train.shape[1]}, Classes: {len(iris.target_names)}\")\n",
        "\n",
        "# TODO: Complete the rest of the implementation\n",
        "# 1. Create datasets and dataloaders\n",
        "# 2. Define a neural network\n",
        "# 3. Train the model\n",
        "# 4. Evaluate accuracy"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class IrisClassifier(nn.Module):\n",
        "  def __init__(self, num_features):\n",
        "    super().__init__()\n",
        "\n",
        "    self.layers = nn.Sequential(\n",
        "        nn.Linear(num_features, 30),\n",
        "        nn.ReLU(),\n",
        "\n",
        "        nn.Linear(30, 15),\n",
        "        nn.ReLU(),\n",
        "\n",
        "        nn.Linear(15, 3)\n",
        "    )\n",
        "\n",
        "  def forward(self, x):\n",
        "      return self.layers(x)\n"
      ],
      "metadata": {
        "id": "fzy4EDll69cy"
      },
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_features = X_train.shape[1]\n",
        "print(\"Number of featuares : \", num_features)"
      ],
      "metadata": {
        "id": "GQlAtHWy8JT4",
        "outputId": "c8fd02d5-1af2-4bec-bb4d-0737477242cd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of featuares :  4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "\n",
        "train_dataset = TensorDataset(X_train, y_train)\n",
        "test_dataset = TensorDataset(X_test, y_test)\n",
        "\n",
        "batch_size = 16\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, drop_last=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "classifier = IrisClassifier(num_features)\n",
        "classifier.to(device)\n",
        "optim = torch.optim.SGD(classifier.parameters(), lr=1e-3)"
      ],
      "metadata": {
        "id": "l5TtPnDZ76--"
      },
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 100\n",
        "optimizer = torch.optim.SGD(classifier.parameters(), lr=0.01)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "  classifier.train()\n",
        "  epoch_loss = 0.0\n",
        "\n",
        "  for _, (features, labels) in enumerate(train_loader):\n",
        "      features, labels = features.to(device), labels.to(device)\n",
        "\n",
        "      logits = classifier(features)\n",
        "      loss = criterion(logits, labels)\n",
        "      optimizer.zero_grad()\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "\n",
        "      epoch_loss += loss.item()\n",
        "\n",
        "  # Print progress every 10 epochs\n",
        "  if (epoch + 1) % 10 == 0:\n",
        "      avg_loss = epoch_loss / len(train_loader)\n",
        "      print(f\"Epoch {epoch+1}/{num_epochs} | Loss: {avg_loss:.4f}\")"
      ],
      "metadata": {
        "id": "e40m8JOj8kal",
        "outputId": "5549b467-2468-4409-c5e3-b2d88da32353",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10/100 | Loss: 0.0768\n",
            "Epoch 20/100 | Loss: 0.0763\n",
            "Epoch 30/100 | Loss: 0.0731\n",
            "Epoch 40/100 | Loss: 0.0609\n",
            "Epoch 50/100 | Loss: 0.0725\n",
            "Epoch 60/100 | Loss: 0.0700\n",
            "Epoch 70/100 | Loss: 0.0579\n",
            "Epoch 80/100 | Loss: 0.0681\n",
            "Epoch 90/100 | Loss: 0.0672\n",
            "Epoch 100/100 | Loss: 0.0519\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluation\n",
        "classifier.eval()\n",
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "    for features, labels in test_loader:\n",
        "        features = features.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        logits = classifier(features)\n",
        "        predictions = torch.argmax(logits, dim=1)\n",
        "\n",
        "        total += labels.size(0)\n",
        "        correct += (predictions == labels).sum().item()\n",
        "\n",
        "accuracy = 100 * correct / total\n",
        "print(f\"\\nTest Accuracy: {accuracy:.2f}%\")\n",
        "\n",
        "# Optional: Show predictions for a few samples\n",
        "print(\"\\nSample predictions:\")\n",
        "with torch.no_grad():\n",
        "    sample_features = X_test[:5].to(device)\n",
        "    sample_labels = y_test[:5]\n",
        "    sample_logits = classifier(sample_features)\n",
        "    sample_preds = torch.argmax(sample_logits, dim=1).cpu()\n",
        "\n",
        "    for i in range(5):\n",
        "        print(f\"True: {iris.target_names[sample_labels[i]]} | \"\n",
        "              f\"Predicted: {iris.target_names[sample_preds[i]]}\")"
      ],
      "metadata": {
        "id": "YjMRsMp3Dq2O",
        "outputId": "e6e23411-5474-4f1a-a682-8710c8dcc1dd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test Accuracy: 100.00%\n",
            "\n",
            "Sample predictions:\n",
            "True: versicolor | Predicted: versicolor\n",
            "True: setosa | Predicted: setosa\n",
            "True: virginica | Predicted: virginica\n",
            "True: versicolor | Predicted: versicolor\n",
            "True: versicolor | Predicted: versicolor\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Set device\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# Load Iris dataset\n",
        "iris = load_iris()\n",
        "X, y = iris.data, iris.target\n",
        "\n",
        "# Split and scale\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "# Convert to tensors\n",
        "X_train = torch.FloatTensor(X_train)\n",
        "X_test = torch.FloatTensor(X_test)\n",
        "y_train = torch.LongTensor(y_train)\n",
        "y_test = torch.LongTensor(y_test)\n",
        "\n",
        "print(f\"Dataset: {len(X_train)} training, {len(X_test)} test samples\")\n",
        "print(f\"Features: {X_train.shape[1]}, Classes: {len(iris.target_names)}\")\n",
        "\n",
        "# Create datasets and dataloaders\n",
        "train_dataset = TensorDataset(X_train, y_train)\n",
        "test_dataset = TensorDataset(X_test, y_test)\n",
        "\n",
        "batch_size = 16\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "# Define neural network\n",
        "class IrisClassifier(nn.Module):\n",
        "    def __init__(self, num_features):\n",
        "        super().__init__()\n",
        "\n",
        "        self.layers = nn.Sequential(\n",
        "            nn.Linear(num_features, 30),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(30, 15),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(15, 3)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.layers(x)\n",
        "\n",
        "# Initialize model\n",
        "num_features = X_train.shape[1]\n",
        "classifier = IrisClassifier(num_features)\n",
        "classifier.to(device)\n",
        "\n",
        "# Define optimizer and loss function\n",
        "optimizer = torch.optim.SGD(classifier.parameters(), lr=0.01)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Training loop\n",
        "num_epochs = 100\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    classifier.train()\n",
        "    epoch_loss = 0.0\n",
        "\n",
        "    for batch_idx, (features, labels) in enumerate(train_loader):\n",
        "        features = features.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        # Forward pass\n",
        "        logits = classifier(features)\n",
        "        loss = criterion(logits, labels)\n",
        "\n",
        "        # Backward pass\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        epoch_loss += loss.item()\n",
        "\n",
        "    # Print progress every 10 epochs\n",
        "    if (epoch + 1) % 10 == 0:\n",
        "        avg_loss = epoch_loss / len(train_loader)\n",
        "        print(f\"Epoch {epoch+1}/{num_epochs} | Loss: {avg_loss:.4f}\")\n",
        "\n",
        "# Evaluation\n",
        "classifier.eval()\n",
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "    for features, labels in test_loader:\n",
        "        features = features.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        logits = classifier(features)\n",
        "        predictions = torch.argmax(logits, dim=1)\n",
        "\n",
        "        total += labels.size(0)\n",
        "        correct += (predictions == labels).sum().item()\n",
        "\n",
        "accuracy = 100 * correct / total\n",
        "print(f\"\\nTest Accuracy: {accuracy:.2f}%\")\n",
        "\n",
        "# Optional: Show predictions for a few samples\n",
        "print(\"\\nSample predictions:\")\n",
        "with torch.no_grad():\n",
        "    sample_features = X_test[:5].to(device)\n",
        "    sample_labels = y_test[:5]\n",
        "    sample_logits = classifier(sample_features)\n",
        "    sample_preds = torch.argmax(sample_logits, dim=1).cpu()\n",
        "\n",
        "    for i in range(5):\n",
        "        print(f\"True: {iris.target_names[sample_labels[i]]} | \"\n",
        "              f\"Predicted: {iris.target_names[sample_preds[i]]}\")"
      ],
      "metadata": {
        "id": "Niuf31S1CBIG",
        "outputId": "7903af97-c61d-44b8-ddf9-8962f7cf934f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cpu\n",
            "Dataset: 120 training, 30 test samples\n",
            "Features: 4, Classes: 3\n",
            "Epoch 10/100 | Loss: 0.9628\n",
            "Epoch 20/100 | Loss: 0.7680\n",
            "Epoch 30/100 | Loss: 0.6086\n",
            "Epoch 40/100 | Loss: 0.5025\n",
            "Epoch 50/100 | Loss: 0.4120\n",
            "Epoch 60/100 | Loss: 0.3515\n",
            "Epoch 70/100 | Loss: 0.3163\n",
            "Epoch 80/100 | Loss: 0.2819\n",
            "Epoch 90/100 | Loss: 0.2411\n",
            "Epoch 100/100 | Loss: 0.2303\n",
            "\n",
            "Test Accuracy: 93.33%\n",
            "\n",
            "Sample predictions:\n",
            "True: versicolor | Predicted: versicolor\n",
            "True: setosa | Predicted: setosa\n",
            "True: virginica | Predicted: virginica\n",
            "True: versicolor | Predicted: versicolor\n",
            "True: versicolor | Predicted: virginica\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "datascience",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.5"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}